[(0.0, 23.66)]:  All right, everybody. Welcome, welcome, welcome, welcome. First breakout of Build. I'm Barnum Bora, and I lead the developer advocacy team for Microsoft 365 and Copilot Platform.
[(23.66, 24.34)]:  advocacy team for Microsoft 365 and Copilot platform.
[(27.92, 28.12)]:  But without further ado, before I come back and do more things,
[(31.98, 36.16)]:  I'm going to hand off to my good friend Jeremy Thake, and he's going to walk you through the first half of this session. Thanks, Barno. I appreciate it. And thank you for coming to Build.
[(37.96, 40.28)]:  So I'm Jeremy Thake. I'm a
[(40.28, 44.1)]:  principal program manager in the Copilot developer experience team. And a slight
[(44.1, 46.34)]:  plug, you may have heard my voice before.
[(46.34, 49.94)]:  I've run a developer podcast on Microsoft 365 for the last ten years.
[(49.94, 52.06)]:  And we've just rebooted the show this week.
[(52.06, 55.7)]:  So if you haven't checked it out, please go on our podcasting apps of choice and download
[(55.7, 57.78)]:  the latest episode.
[(57.78, 60.52)]:  So you're going to see a lot about Copilot this week.
[(60.52, 67.94)]:  I believe there may be some drinking games going on on how many times we mention copilot in a particular session. So copilot, copilot, copilot, copilot. There we go. We
[(67.94, 72.84)]:  get that out of the way. You would have seen this slide in the keynote.
[(72.84, 76.98)]:  And I think it's just worth just revisiting it with a different flavor to it. Essentially
[(76.98, 88.1)]:  when we think about copilot for Microsoft 365, not only do you get access to all of the web information out there if you choose to turn the toggle on, but you also most importantly get access to all that graph data.
[(88.1, 91.68)]:  And I've worked with the Microsoft Graph for a long time and we have some of the founders
[(91.68, 93.62)]:  of the Graph sitting at the front here.
[(93.62, 99.28)]:  And it really empowers how Copilot works from a product perspective for users.
[(99.28, 106.18)]:  Now the nice thing is that can be done and used within the application context of Teams, Office.com, Windows, Edge,
[(106.18, 110.66)]:  and you can make those queries all in that case not only with the web search but with
[(110.66, 117.18)]:  that M365 data, whether it's files, mail, calendar, contacts, wherever it's Teams conversations,
[(117.18, 119.42)]:  and a lot more to come in the future.
[(119.42, 124.6)]:  And you as developers, whether you're makers or pro code developers, can extend both the
[(124.6, 125.16)]:  Microsoft Graph and the application context to make that experience even better for your developers, whether you're makers or pro code developers, can extend both the Microsoft
[(125.16, 129.18)]:  Graph and the application context to make that experience even better for your users
[(129.18, 131.5)]:  inside of Microsoft 365.
[(131.5, 137.06)]:  Now, there are lots of opportunity inside of Microsoft 365.
[(137.06, 141.66)]:  And one thing I wanted to recall was essentially that we have lots of customers in common,
[(141.66, 149.1)]:  whether you're a software vendor or a customer that are using our products because they trust it and they trust our partners with how we can extend our platforms.
[(150.24, 154.88)]:  And additionally to that, one of the things that's going to become very, very clear to
[(154.88, 156.82)]:  you today is we're giving you a lot of choice.
[(157.38, 162.16)]:  You can either build on top of our AI platform or you can bring your own AI platform into
[(162.16, 163.1)]:  ours and extend it.
[(163.66, 167.88)]:  Now, users are really used to accessing not only M365 data
[(167.88, 171.22)]:  within our products, but also accessing your other systems,
[(171.22, 173.6)]:  whether you're a software vendor with a SaaS company,
[(173.6, 175.6)]:  or whether you've got your internal systems, maybe
[(175.6, 177.56)]:  on-premises systems, that you want to bring up
[(177.56, 180.48)]:  into that Microsoft 365 experience.
[(180.48, 182.28)]:  Now, we've mentioned numbers in the past,
[(182.28, 184.32)]:  but there's a tremendous amount of reach
[(184.32, 187.28)]:  with Microsoft Teams and other products that you're familiar with within our suite.
[(187.88, 199.58)]:  And the opportunity of having 320 million users of Teams every month is a real huge opportunity for you to build on top of and be part of this experience we have now, especially with lighting up artificial intelligence inside of it.
[(200.98, 205.24)]:  Not only can you summarize that information that comes through with M365 data with your
[(205.24, 208.32)]:  system data, but now you can actually act on it.
[(208.32, 211.12)]:  And you would have seen some of that in the keynote this morning, and we'll show you some
[(211.12, 215.22)]:  more demos today from some of our partners that are highlighting how you can act on data
[(215.22, 217.74)]:  as well as summarize.
[(217.74, 221.3)]:  And obviously, as Jeff mentioned, we have a huge ecosystem there that you can be a part
[(221.3, 229.32)]:  of where you can bring and expand your customer base as a software vendor and also from a private store have your own users within your organization
[(229.32, 236.9)]:  be available and see what solutions they can use within their own Microsoft 365 hubs.
[(236.9, 241.18)]:  Now as I've mentioned before, whether you're a maker in Copilot Studio or whether you're
[(241.18, 245.38)]:  a Pro Code developer in Visual Studio Code using Teams toolkit, we have choices
[(245.38, 248.38)]:  for you today.
[(248.38, 253.54)]:  And I think what I wanted to do was basically ground what we mean by the AI platform with
[(253.54, 258.64)]:  inside of Copilot for Microsoft 365.
[(258.64, 261.64)]:  Now you would be familiar with some terms that have been going on in the industry.
[(261.64, 269.98)]:  And I've been working in this space now for nearly two years, both in the internal builds before we announced at Build last year, and
[(269.98, 273.02)]:  some of the terms I just wanted to recapture with you just so you understand how we're
[(273.02, 276.96)]:  talking about them in terms of the different choices you have.
[(276.96, 283.26)]:  So as a first example here, when we talk about foundational models, that's kind of the base
[(283.26, 287.94)]:  that Kevin Scott would have talked about in the keynote this morning of which large language models you are using
[(287.94, 292.18)]:  or small language models you are using inside of your copilot.
[(292.18, 293.82)]:  And the orchestrator is really the brains.
[(293.82, 297.0)]:  That's the thing that takes all the data at the top of the stack and brings it to the
[(297.0, 301.06)]:  large language model to then understand what it does with it and how it responds to the
[(301.06, 309.72)]:  user, and then the orchestrator throws that back up to the user in our user experience. And the key thing is by default the orchestrator has access to this knowledge
[(309.72, 317.0)]:  and that knowledge is the M365 data that's inside of that Microsoft Graph.
[(317.0, 321.44)]:  But what we're seeing with AI platforms is this notion of triggers. And triggers is that
[(321.44, 328.22)]:  concept of being able to proactively reach out to your user through that copilot to do certain things based on events happening in other systems.
[(328.76, 334.12)]:  You'd see this traditionally in things like how we use webhooks or change notifications in the graph.
[(334.32, 340.4)]:  But now we're bringing that triggers concept in the concept of how we use Microsoft 365 copilot and other AI platforms.
[(342.08, 345.5)]:  And then alongside knowledge as a way to get access to information, we have
[(345.5, 351.3)]:  this notion of actions. And actions is all about calling out to external systems outside
[(351.3, 356.1)]:  of the knowledge that the orchestrator has access to to get information from other systems.
[(356.1, 359.88)]:  And these are federated API calls, whether I'm using the semantic kernel, whether I'm
[(359.88, 366.68)]:  using Copart for Microsoft 365 or any other BYO AI platform stack you're bringing.
[(371.32, 372.46)]:  And what we've seen very, very early on with AI is that you like to tailor what that large language model can do.
[(373.18, 376.54)]:  And so some of the things we've announced today essentially allow you to bring your
[(376.54, 381.1)]:  own instructions to tailor how a large language model and how the Copilot user experience
[(381.1, 383.9)]:  works to customize it for the user scenarios you have.
[(383.94, 387.5)]:  And the demos will show, will bring this into account.
[(387.5, 392.22)]:  Now the reason I'm explaining this stack is for this next build, which is essentially
[(392.22, 397.12)]:  that with those choices, there are a few ways, a few paths you can take.
[(397.12, 402.34)]:  Now naturally when we talk about M365 and we talk about copilot for Microsoft 365, we
[(402.34, 412.64)]:  have the identity of the user that's logged into Teams or into the Microsoft 365 app or the Copilot.Microsoft.com web application. We're using our own foundational
[(412.64, 416.62)]:  model in that instance and we have our own orchestrator which you've heard Kevin Stott
[(416.62, 421.66)]:  talk about from a Sydney perspective. And the knowledge is Microsoft Graph knowledge,
[(421.66, 430.5)]:  but you can bring your own data into it. And we provide this copilot across all the different Microsoft 365 hubs.
[(430.5, 435.16)]:  So our first choice that you can pick from is Graph Connectors.
[(435.16, 440.1)]:  And effectively what Graph Connectors do is bring additional semantic grounding directly
[(440.1, 444.66)]:  into the Microsoft Graph that the orchestrator has access to.
[(444.66, 448.94)]:  And the important part with this is that you can put all of that knowledge directly in
[(448.94, 451.12)]:  there for the orchestrator to query.
[(451.12, 454.9)]:  And that brings some scenarios that are very, very different from some of the other choices
[(454.9, 457.82)]:  that we offer on the table.
[(457.82, 461.58)]:  As an example, when we talk about plug-ins, which is that second choice, again, both of
[(461.58, 469.0)]:  these we announced at Build last year in public preview. Plug-ins are actually doing an action. They're calling out to a system via an API
[(469.0, 474.64)]:  or a bot command. And so they're not part of the knowledge stack within the AI platform.
[(474.64, 479.28)]:  They're a little bit higher up. And that provides different alternatives and different pros
[(479.28, 483.26)]:  and cons that we'll talk about as part of this session.
[(483.26, 490.86)]:  What we announced new today is what we call declarative coilots. And a declarative copilot allows you to provide those custom work instructions
[(490.86, 496.4)]:  to really tailor how your large language model works. And the nice thing about a declarative
[(496.4, 502.12)]:  copilot is you can bring both plug-ins and graph connectors and bundle those in a declarative
[(502.12, 506.0)]:  copilot alongside those custom workflow instructions.
[(506.0, 510.7)]:  Now, all of these choices are on top of our stack.
[(510.7, 513.6)]:  They're on our AI platform.
[(513.6, 517.74)]:  But we know from talking to customers for the last two years on this stuff that you're
[(517.74, 522.96)]:  also investigating your own AI platforms and you've asked for the ability to bring those
[(522.96, 528.4)]:  AI platforms within our experiences alongside what we offer on top of their own stack.
[(528.4, 534.08)]:  And so in this case, with what we call custom engine co-pilots, you have the ability to
[(534.08, 536.68)]:  essentially BYO.
[(536.68, 540.32)]:  And the benefit of this notion of bring your own is that not only can you be part of our
[(540.32, 545.76)]:  user experience, you can also be part of your own user experience with the same
[(545.76, 550.32)]:  I.I. platform. And so today we're going to walk through all of these different options
[(550.32, 555.6)]:  and choices so that you understand not at a visual level that we saw in the keynote
[(555.6, 559.24)]:  but in a decision process as a maker or developer right now on what you should be doing this
[(559.24, 568.78)]:  week. So let's start with Graph Connectors. Graph Connectors, as I say, have been around for
[(568.78, 573.14)]:  about four years in the platform. And obviously with Copilot, we realized we had a really
[(573.14, 577.4)]:  good shoe-in ramp to take the existing Graph Connectors we have, the power of Microsoft
[(577.4, 583.6)]:  Search, and take advantage of those as knowledge with the inside of Copilot for Microsoft 365.
[(583.6, 589.04)]:  Now you've just seen Rajesh on stage announce Copilot connectors as an overarching term.
[(589.04, 593.02)]:  Now one piece of clarity I want to bring to the table here is that the Microsoft Graph
[(593.02, 599.24)]:  connectors are the only connectors that bring the information directly into the knowledge
[(599.24, 601.4)]:  part of the stack.
[(601.4, 604.78)]:  All of the Copilot Studio connectors that you can see on the right-hand side of this
[(604.78, 609.12)]:  slide are actually plug-ins. They're wrapped plug-ins from existing technology
[(609.12, 614.48)]:  we have in the Power Platform stack, whether they're Power Platform connectors, flows,
[(614.48, 619.62)]:  Dataverse connectors or Microsoft Fabric connectors. And so there's a little difference between
[(619.62, 624.5)]:  when you're picking those copilot studio connectors versus this Graph connector which gets straight
[(624.5, 629.3)]:  into that knowledge of the stack. Now, one of the main benefits that people
[(629.3, 634.92)]:  pick Graph connectors as their choice is that effectively when you push that data into the
[(634.92, 639.36)]:  Microsoft Graph, it's in the index of the Microsoft Graph, whenever the orchestrator
[(639.36, 644.96)]:  uses a prompt like can you give me guidance on operational efficiency, the orchestrator
[(644.96, 645.64)]:  is never having
[(645.64, 650.72)]:  to call anything outside the Microsoft boundary because a graph connector is pushing that
[(650.72, 655.24)]:  content into Microsoft Graph. Your system is pushing information into the Microsoft
[(655.24, 660.04)]:  Graph and there's never any calls that come outside.
[(660.04, 668.78)]:  Now where do graph connectors make the most sense? Like most search indexes, unstructured data is really where it sings.
[(668.78, 673.46)]:  Anything you can take a bunch of information and flatten it into a JSON file or plain text
[(673.46, 677.06)]:  file and throw that through the Microsoft Graph to get it in our index is really where
[(677.06, 679.56)]:  it's going to make most sense.
[(679.56, 684.24)]:  And large language models do a really good job of taking that flattened content and using
[(684.24, 685.24)]:  it in summarization.
[(685.24, 688.88)]:  You'll see that in some of the partner demos we'll show today.
[(688.88, 694.8)]:  Now the beauty of this, in my opinion, is that you don't have to plan much about what
[(694.8, 697.8)]:  prompts you think your users are going to go do.
[(697.8, 702.76)]:  Because if you're indexing the entire page, much like a Copilot index is a public website,
[(702.76, 705.42)]:  you can ask it questions in all different ways because
[(705.42, 708.18)]:  it's indexing that into a vector database.
[(708.18, 711.16)]:  And so I can get quite random prompts that I can ask.
[(711.16, 715.44)]:  And as long as the answer is in the page, most likely the orchestrator and the copilot
[(715.44, 719.22)]:  is going to work together to make sure that it can find that answer and respond to that
[(719.22, 720.22)]:  user.
[(720.22, 724.72)]:  So the notion of unpredictable prompts on large sets of information that's unstructured
[(724.72, 727.68)]:  is really, really valuable when it comes to graph connectors.
[(727.68, 732.32)]:  A thing to call out is obviously the fact that it's punching things into the index in
[(732.32, 737.96)]:  the Microsoft graph means that from a scalability perspective and us defending our API and our
[(737.96, 743.2)]:  service quality, we can't really have you indexing systems that are very high throughput,
[(743.2, 745.24)]:  very high transactions.
[(745.24, 750.62)]:  And so we look for systems in this place that are more low activity updated items.
[(750.62, 754.7)]:  And so good candidates for that for the Graph Connectors are things like document repositories.
[(754.7, 758.44)]:  They could be other SaaS providers that you use within your organization or you could
[(758.44, 761.76)]:  be the vendor that's running those document repositories.
[(761.76, 765.12)]:  It could be a knowledge base that's running in the cloud like a wiki.
[(765.12, 770.76)]:  You could be on a public website or an internal website. It could be also content management
[(770.76, 774.38)]:  systems that you're running for your intranet that might not be SharePoint. You've chosen
[(774.38, 778.48)]:  to use another product in the ecosystem. All of these things are really good candidates
[(778.48, 782.56)]:  for being put through as an index for Graph Connectors.
[(782.56, 785.84)]:  Now this first demo is from a partner called Tiger Hall. And Tiger
[(785.84, 790.9)]:  Hall has been working with us in private preview for a while. And this demo is a really good
[(790.9, 796.18)]:  explanation of how things work in Copilot. They've indexed videos and they've indexed
[(796.18, 799.9)]:  their articles that they store within their own product. And essentially what you'll see
[(799.9, 805.34)]:  here is the user is asked about how he can be more strategic. And that video has actually
[(805.34, 811.14)]:  been replayed, clicked on, launches in Teams. The user never leaves the flow of the work.
[(811.14, 816.7)]:  But as another example here with what is operational scalability, you'll notice that it's giving
[(816.7, 822.28)]:  nice long form responses and I have the ability to launch the article directly inside of Tiger
[(822.28, 830.52)]:  Hall. These are both really good examples of how you can get content into Graph Connectors, into the Microsoft Graph, and then just immediately
[(830.52, 835.7)]:  start prompts without having to app mention plug-ins or launch your declarative copilots,
[(835.7, 839.78)]:  which we'll see in a moment, and just have that knowledge available to that copilot in
[(839.78, 845.88)]:  that way. This is a great way of connecting your business information directly into M365.
[(849.44, 855.88)]:  Now, if I go over to some code just to show you how you can get started as a developer here, I'm just going to switch over to my machine. You'll see I have some code on the
[(855.88, 870.14)]:  screen. No, you don't. There we go. And this sample is available online. Essentially, if you have Teams Talk installed on your machine, there is a sample section
[(870.14, 872.52)]:  where you can search for Graph Connectors.
[(872.52, 877.18)]:  And this one is called the ingest custom API data into Microsoft 365.
[(877.18, 881.24)]:  There's a great read me on how you get started with this inside of your own Microsoft 365
[(881.24, 882.24)]:  tenant.
[(882.24, 885.16)]:  And the one thing I wanted to call out here is that if you've already used
[(885.16, 890.34)]:  the Microsoft Graph APIs and you've used our SDKs, this is going to become smooth sailing for you.
[(891.3, 895.16)]:  Effectively, you're providing a schema of what your indexed item looks like.
[(895.66, 900.88)]:  You can have custom properties to really tie in and tune in what that search experience looks like.
[(901.86, 905.0)]:  And then you can provide the level of the content here. And in this example,
[(905.0, 908.5)]:  we're very straightforward with the content is just the product name. But you can imagine
[(908.5, 913.16)]:  that being the body of the entire article so that the knowledge is very deep inside
[(913.16, 918.68)]:  of that experience. Now, what does that look like with inside of Microsoft 365? If you're
[(918.68, 923.5)]:  a search admin or you're a global admin on a developer tenant like I am where you can
[(923.5, 925.5)]:  do all sorts of trouble.
[(925.5, 928.5)]:  You'll see in the Search Intelligence Center that they list all of the different Graph
[(928.5, 930.2)]:  Connectors that have been deployed.
[(930.2, 935.56)]:  And you'll be able to see here we've indexed 50 items inside of that connected content.
[(935.56, 942.64)]:  Now, the beauty of this is that that shows up in Microsoft Search.
[(942.64, 946.74)]:  And so we can search for under the Graph graph connector vertical there or even the all bucket.
[(947.26, 950.42)]:  And that will list all the different chocolate that we've indexed inside there.
[(950.5, 954.5)]:  And you can have adaptive cards to control exactly how that renders in Microsoft Search.
[(954.56, 957.6)]:  And that technology has been in our platform for a long time now, generally available.
[(958.72, 961.84)]:  But in addition to that, we can start making queries there.
[(961.84, 964.52)]:  Like what countries is dairy milk sold in?
[(968.38, 968.9)]:  And you'll see that it's given a citation here of the World Open Food Facts.
[(974.66, 978.52)]:  And if I launch that there, what you'll see is that that's given me the information about dairy milk. And it's essentially not only have we injected the properties directly into the page,
[(978.58, 982.14)]:  but it's using the whole scraped page of that as well to make those answers.
[(982.76, 991.32)]:  So just a quick example of how you can use a graph connector to pull information through. And, again, just use the Teams toolkit and
[(991.32, 997.24)]:  that sample in there to get that going. So that was graph connectors.
[(997.24, 1006.34)]:  Now, with that, with plug-ins, essentially what we announced last year at Build was message extensions.
[(1006.34, 1011.76)]:  And again, much like Graph Connectors, we wanted to provide a ramp for existing people
[(1011.76, 1015.0)]:  in our ecosystem that have been building extensions for Teams.
[(1015.0, 1016.6)]:  And so those are still supported.
[(1016.6, 1018.66)]:  They're still in public preview.
[(1018.66, 1023.48)]:  But we've announced today with API plug-ins that we wanted to give a little bit more direct
[(1023.48, 1029.88)]:  control of how you can connect to APIs. Message extensions are great if you're in the Teams ecosystem world
[(1029.88, 1034.24)]:  and you want to have things work in Teams chats and have those adaptive calls inject
[(1034.24, 1039.86)]:  straight into concepts and Copilot can call those same bot framework commands. But we
[(1039.86, 1043.5)]:  had a lot of feedback in the last year that we want developers wanted just to have that
[(1043.5, 1049.72)]:  mapping of, look, I've got an open API document with a description of my API and I want our copilot
[(1049.72, 1054.18)]:  to look with its orchestrator and see this plug-in matches, here are the functions that
[(1054.18, 1058.58)]:  make sense for me to call to try and get the answer and let the large language model make
[(1058.58, 1065.1)]:  a decision on whether it should use that particular response from this particular plugin.
[(1065.1, 1069.44)]:  And then the third option, which we announced in November at Ignite, was Copilot Studio
[(1069.44, 1074.42)]:  plugins. Today I'm going to focus on API plugins, and there's some great sessions that will
[(1074.42, 1078.38)]:  go into a lot more depth around the other ways you can do things.
[(1078.38, 1083.68)]:  So if we look at plugins, the difference here, if you notice on the screen, is that API plugins
[(1083.68, 1088.58)]:  leave the Microsoft 365 boundary because it's calling an API that isn't hosted inside of Microsoft 365.
[(1089.26, 1093.42)]:  So that's a choice you have to make by using plugins in this platform.
[(1094.8, 1100.82)]:  Now, plugins are really good for real-time data, and especially so for highly relational data.
[(1101.1, 1104.16)]:  We mentioned with Graph Connectors, you have to flatten that data to put it in the index.
[(1103.64, 1108.6)]:  relational data. We mentioned with Graph Connectors you have to flatten that data to put it in the index. With high relational data, the API, you can build the shapes of your API,
[(1108.74, 1113.08)]:  what parameters you need to be able to get at that highly relational data. With Graph
[(1113.08, 1119.22)]:  Connectors we do have some limits on how much items you can index inside of Microsoft Graph.
[(1119.22, 1123.38)]:  And so if you're dealing with systems that are larger than those limits, then plug-ins
[(1123.38, 1129.56)]:  are going to be the best place for you. Plug-ins really rely on you understanding the precision of the
[(1129.56, 1134.12)]:  prompts your user is going to ask. Show me the latest issues I'm assigned to. Show me
[(1134.12, 1138.64)]:  the projects that I'm assigned to. What are the latest orders that have been reached into
[(1138.64, 1145.74)]:  the system? And the nice thing about plug-ins is as well as being able to summarize the data that you
[(1145.74, 1149.16)]:  can reach out to through those APIs, you can also do actions on it.
[(1149.16, 1153.8)]:  And you saw in Jeff's keynote this ability to go and update the system and confirming
[(1153.8, 1156.18)]:  with Copilot you want to do that update.
[(1156.18, 1160.12)]:  And obviously if you've already got an API in your system, all you have to do is wrap
[(1160.12, 1166.0)]:  that in an open API document, provide a plug-in manifest, and you're off To the races deploying that in your environment.
[(1166.0, 1170.0)]:  It's a good way to get started if you have an api with a good
[(1170.0, 1173.0)]:  Set of crud capabilities on it. Create, read, update, delete.
[(1173.0, 1176.0)]:  Good candidates for plug-ins, as you would expect, all the
[(1176.0, 1180.0)]:  Large enterprise systems that have transactional data or are
[(1180.0, 1183.0)]:  Dealing with customers and the frequency of the items being
[(1183.0, 1188.42)]:  Updated is very, very high. If you have these within your experience or you're a vendor that owns a system like this,
[(1188.78, 1190.2)]:  plugins is going to be a good fit for you.
[(1192.94, 1196.22)]:  Now there are two ways you can build plugins as has been mentioned before.
[(1196.62, 1200.58)]:  First is Copilot Studio and then there is Teams Toolkit and Visual Studio Code.
[(1201.76, 1208.0)]:  If you're familiar with low code, if you've used Power Apps, Power Platform,
[(1208.0, 1212.18)]:  Power Automate, Power Connect, Power Platform connectors, then Copilot Studio is probably
[(1212.18, 1215.18)]:  the best place for you to start because you can take advantage of those things and wrap
[(1215.18, 1220.5)]:  those in plug-ins and deploy them into Copilot. It is a rapid developer environment. And another
[(1220.5, 1225.78)]:  benefit of Copilot Studio is that it's managed infrastructure on your behalf.
[(1233.94, 1234.4)]:  Now, with Teams Toolkit, if you're familiar with managed code, you've written C Sharp, you've written JavaScript, TypeScript, Teams Toolkit is going to be a better spot for you.
[(1242.58, 1248.0)]:  If you've built existing Teams app in Teams Toolkit, you can easily add plugins and graph connectors into them and deploy those into your environment. Teamstalk also gives you the luxury through the CLI to deploy to multiple tenants, which
[(1248.0, 1252.0)]:  gives you kind of release management, branch management, and also if you've got multiple
[(1252.0, 1255.0)]:  customers, the ability to push things out in a very controlled way.
[(1255.0, 1260.0)]:  And obviously because it's managed code, you get the benefits of very fine source control,
[(1260.0, 1267.94)]:  branching and release management procedures that you have within your own teams. Now, obviously, you do need to host your own infrastructure for this.
[(1272.42, 1276.96)]:  So, Tempify is another partner we've been working with, and this is a great example
[(1276.96, 1280.4)]:  of bringing M365 data together with their solution.
[(1281.04, 1284.68)]:  They've asked for the latest communications from Contoso, and what you would have seen
[(1284.68, 1289.44)]:  very briefly in the keynote is a new feature of Copilot for Microsoft 365 which allows
[(1289.44, 1293.8)]:  you to app mention a plug-in. Now, the main reason this is beneficial is because you can
[(1293.8, 1300.16)]:  now really allow Copilot to focus in on just asking Tempify and not the hundreds of plug-ins
[(1300.16, 1310.24)]:  or the hundreds of graph-connected information or the M365 data there, and it's feedback we've had since we've been doing these private previews and public previews.
[(1310.24, 1315.62)]:  After that app mention has happened, essentially what you'll see is that Temporafly will look
[(1315.62, 1321.02)]:  at the information that it got from the communications with Contoso and it will suggest two templates.
[(1321.02, 1326.2)]:  Now as a user, I'm going to go choose the basic template that Tempify has
[(1326.2, 1330.4)]:  picked. And here's a new thing that we're providing inside of Copilot for Microsoft
[(1330.4, 1336.4)]:  365. You now have the ability for Copilot to push information that it got from another
[(1336.4, 1342.18)]:  query that came from M365 in this case and ask the user, are you okay with me sending
[(1342.18, 1345.56)]:  this information to Tempify? And the user explicitly has to
[(1345.56, 1351.08)]:  say confirm to send that information. Tempify creates that sales agreement and the user
[(1351.08, 1354.84)]:  can within the flow of his work launch that document and see that Tempify has built that
[(1354.84, 1360.42)]:  document based on its template with the information it got from the other experience. And so it's
[(1360.42, 1369.4)]:  a really good end-to-end flow that is common in Copilot from a productivity perspective, allowing you to see how our partners out there can leverage plug-ins.
[(1370.3, 1375.8)]:  Now, I've covered those two things real quick because we've got a lot of great content that Barnum's going to cover next.
[(1376.32, 1388.8)]:  There are two essentially good breakouts in BRK148 and 151 that are later on this afternoon in this room. I'd encourage you if you want to go deeper in either of these two things, whether it's choosing Teams Toolkit or Copilot Studio,
[(1389.28, 1394.42)]:  check out those breakouts. I want to cover one last thing before I hand over to Barnum.
[(1395.98, 1400.18)]:  We get this question a lot. How do we start building with Copilot for Microsoft 365?
[(1401.54, 1406.68)]:  If you're in the ISV program that my team runs, you can have access to a private
[(1406.68, 1412.94)]:  preview of what we will launch publicly later in the year. Effectively get three 25 E5 users
[(1412.94, 1418.66)]:  and then you can purchase copilot licenses on top. If you're not an ISV, a software company,
[(1418.66, 1424.64)]:  you can go directly to Microsoft365.com and you can purchase a business basic plan and
[(1424.64, 1426.34)]:  copilot for Microsoft 365 for one
[(1426.34, 1430.6)]:  user and that will get you off to the races building on top of copilot for now.
[(1430.6, 1435.06)]:  And then by the end of the year, we will be announcing that if you have used the M365
[(1435.06, 1439.98)]:  developer program, you will be able to essentially take your tenant and purchase copilot for
[(1439.98, 1448.56)]:  Microsoft 365 on top. This is a journey we're on at the minute in the notion of how quickly we're speeding up. And if you have any feedback, we'd love to hear from it. But that's just
[(1448.56, 1451.26)]:  where we're at right now in terms of how you can get going on the developer side.
[(1452.8, 1457.34)]:  Okay. So I've talked a lot about plug-ins and graph connectors. I'm going to hand over
[(1457.34, 1468.4)]:  to Barnum to talk about how you can bring your own immersive experiences into Copilot for Microsoft 365. Thanks, mate. Thank you.
[(1469.78, 1471.0)]:  It's a hard act to follow, huh?
[(1477.04, 1487.94)]:  Well, we've already talked, you know, Jeremy's given us a great update into essentially the, how you add additional semantic grounding through connectors and how you also are able to connect to your source systems
[(1487.94, 1491.08)]:  or other systems of record in your business using plugins,
[(1491.34, 1493.22)]:  both for actions and for retrieval.
[(1494.02, 1497.16)]:  Now, what these technologies essentially do
[(1497.16, 1501.42)]:  is they widen the scope of what Copilot,
[(1501.84, 1504.9)]:  that's built by Microsoft, is able to do for you.
[(1503.38, 1504.9)]:  of what Copilot that's built by Microsoft is able to do for you.
[(1505.94, 1510.66)]:  But in our work with our early access customers and partners
[(1510.66, 1514.2)]:  and also as we get ourselves more and more involved
[(1514.2, 1516.24)]:  in the research of building these systems,
[(1516.72, 1519.46)]:  we realize that focused experiences
[(1519.46, 1520.58)]:  is also a requirement
[(1520.58, 1523.06)]:  where we actually need to narrow down
[(1523.06, 1528.44)]:  the bandwidth of what the specific co-pilot
[(1528.44, 1534.04)]:  experience needs to focus on. And that's why we, you've seen in the keynote, we've launched this
[(1534.04, 1539.98)]:  notion of your own co-pilots. Your own co-pilots are effectively instantiations of co-pilot,
[(1540.44, 1546.3)]:  which have your own specific business context, your own applications are plugged into it already,
[(1546.78, 1548.72)]:  and your workflows are plugged into it,
[(1548.8, 1550.36)]:  and maybe your automation as well.
[(1552.24, 1554.3)]:  One of the benefits of building this,
[(1554.3, 1555.62)]:  we've already announced that,
[(1555.82, 1558.68)]:  is that you can actually take your own custom,
[(1558.92, 1561.78)]:  these co-pilots that you build and instantiate on top of us
[(1561.78, 1564.4)]:  and publish them as co-pilot extensions.
[(1564.74, 1566.52)]:  So essentially, you're not missing out.
[(1567.1, 1569.06)]:  Effectively, your co-pilots show up
[(1569.06, 1570.94)]:  very similar to how plugins would show up
[(1570.94, 1573.6)]:  in our co-pilot experiences across our hubs,
[(1574.0, 1576.64)]:  but it will also be available
[(1576.64, 1580.36)]:  in your own immersive experience as well.
[(1581.06, 1582.98)]:  We are trying to make it very easy for you
[(1582.98, 1584.12)]:  to publish these co-pilots
[(1584.12, 1585.18)]:  through a click-through experience onpilots through a click-through
[(1585.18, 1590.14)]:  experience on SharePoint or through a click-through experience on Co-Pilot Studio or on VS Code in a
[(1590.14, 1596.66)]:  development environment. Now, moving into this stack slide that Jeremy covered before,
[(1597.22, 1605.24)]:  effectively, there are two forms, two large forms of your own co-pilots. Let's talk about the first one, which is declarative co-pilots.
[(1605.84, 1611.84)]:  You've heard this term today a few times. Declarative co-pilots is essentially the kind
[(1611.84, 1617.68)]:  of co-pilot where you've actually taken the engine that Microsoft has already built in our
[(1617.68, 1627.32)]:  own Microsoft co-pilot and added some declarative instructions on top of it. So you're not necessarily messing with the innards of the LLM model itself,
[(1627.54, 1631.28)]:  but what you've given to it is a specific set of instructions
[(1631.28, 1634.4)]:  set on top that gives it the personality or the focus.
[(1635.78, 1639.92)]:  What do these declarative co-pilots really help out in?
[(1640.18, 1642.98)]:  Effectively, you know, we all work in organizations,
[(1643.46, 1645.22)]:  and some of us are generalists
[(1645.22, 1646.34)]:  and some of us are specialists.
[(1647.06, 1651.32)]:  When you want specialist behavior of your co-pilot,
[(1651.5, 1652.84)]:  you know, think of Microsoft co-pilot
[(1652.84, 1655.2)]:  as the generalist, full-capacity co-pilot.
[(1655.2, 1657.54)]:  Then you want specific specialist behavior,
[(1657.72, 1660.16)]:  maybe for your HR, for your IT, you know,
[(1660.38, 1661.74)]:  all of these kind of behaviors,
[(1662.02, 1664.68)]:  where you want it to focus on a specific area
[(1664.68, 1665.84)]:  or specific documentation,
[(1666.4, 1668.5)]:  that's when declarative co-pilots come to play.
[(1669.16, 1671.06)]:  Effectively, they are Microsoft co-pilot
[(1671.06, 1672.08)]:  plus your instructions,
[(1672.7, 1676.96)]:  which in reality just gives co-pilot more context
[(1676.96, 1679.36)]:  to do generations that are more relevant to you.
[(1680.12, 1681.68)]:  What's important to also note
[(1681.68, 1688.24)]:  that this context is actually a combination of a few very simple things.
[(1688.86, 1690.94)]:  These are your declarative custom instructions,
[(1691.04, 1692.1)]:  and we'll look at that very shortly.
[(1692.66, 1694.72)]:  Effectively, you have your custom prompt instructions,
[(1694.72, 1698.22)]:  which are your natural language prompt that instantiates it.
[(1698.5, 1700.06)]:  You have the additional grounding data.
[(1700.18, 1701.54)]:  You can point to a SharePoint site
[(1701.54, 1703.5)]:  or maybe upload new data, et cetera.
[(1704.34, 1707.68)]:  And you also encapsulate your plugins and connectors
[(1707.68, 1708.88)]:  into that one thing.
[(1709.96, 1713.1)]:  What I want to actually show you after this
[(1713.1, 1715.54)]:  is that you can encapsulate that
[(1715.54, 1717.98)]:  into a single copilot experience
[(1717.98, 1720.1)]:  on top of Microsoft 365 Copilot
[(1720.1, 1722.92)]:  and deploy that as your own copilot.
[(1723.28, 1761.26)]:  Let's look at VS Code. Well, effectively, the custom instructions
[(1761.26, 1763.56)]:  that I was talking about on your screen,
[(1764.98, 1766.0)]:  you've got your...
[(1766.0, 1769.34)]:  This is a VS Code project
[(1769.34, 1770.84)]:  where you've actually...
[(1770.84, 1772.36)]:  We've gone ahead and created
[(1772.36, 1775.26)]:  a declarative copilot.
[(1775.7, 1777.62)]:  Effectively, it's a combination of those three things
[(1777.62, 1778.52)]:  that we just spoke about.
[(1778.82, 1781.22)]:  It's your custom instruction set in plain language.
[(1782.1, 1784.04)]:  And I've gone ahead and identified
[(1784.04, 1786.36)]:  and instantiated a few conversation
[(1786.36, 1789.66)]:  starters for your immersive experience, which actually prompts the user to say, hey, let's
[(1789.66, 1793.68)]:  go have this conversation this way. And then I've said, I've pointed to a SharePoint
[(1793.68, 1799.32)]:  site, which actually has effectively now it knows that, hey, the documents in the SharePoint
[(1799.32, 1803.8)]:  site are the ones that I need to focus on, and then the actions is effectively a plug-in
[(1803.8, 1808.64)]:  that I've encapsulated into this particular declarative copilot.
[(1815.66, 1820.14)]:  Now, these declarative copilots, obviously, you can build them through VS Code or through
[(1820.14, 1826.2)]:  Copilot Studio. The beauty of it is they can appear in context and in your focused immersive experience as well.
[(1827.46, 1829.4)]:  So let's talk about why would you do
[(1829.4, 1830.34)]:  these declarative copilots
[(1830.34, 1832.06)]:  and what are the sort of specific scenarios
[(1832.06, 1833.98)]:  where they really become powerful.
[(1834.9, 1836.36)]:  Any scenario, as I said,
[(1836.44, 1838.4)]:  that requires focus or specialization
[(1838.4, 1840.18)]:  where you want to give it nuance.
[(1841.08, 1843.04)]:  Any scenario where you want to layer
[(1843.04, 1844.62)]:  on top of the existing capability
[(1844.62, 1846.0)]:  of Microsoft 365 Copilot. Any scenario where you want to layer on top of the existing capability of Microsoft 365 Copilot,
[(1846.0, 1851.0)]:  any scenario where you want to target specific roles in your organization or your customer set,
[(1851.0, 1855.0)]:  and any scenario where you want to scope it to specific data sources.
[(1855.0, 1859.0)]:  These are great examples of where declarative copilots are powerful.
[(1859.0, 1863.0)]:  Here's a point I actually want to focus on myself.
[(1863.0, 1866.14)]:  You know, a plug-in gives you data.
[(1866.24, 1869.02)]:  For example, you know, it might be a JSON response
[(1869.02, 1871.34)]:  through an API or you're looking at a database
[(1871.34, 1872.5)]:  and getting structured data.
[(1873.08, 1877.44)]:  Sometimes you need to add nuance or domain understanding
[(1877.44, 1879.08)]:  of how to interpret that data.
[(1879.76, 1881.78)]:  That's not possible just through a plug-in
[(1881.78, 1883.02)]:  because you're getting raw data.
[(1883.8, 1885.66)]:  So when you add that nuance
[(1885.66, 1887.92)]:  into your declarative custom instruction,
[(1888.02, 1889.8)]:  say, hey, when I read this type of data,
[(1890.04, 1890.8)]:  this is what it means.
[(1891.44, 1893.58)]:  That's one of the powers of declarative copilot
[(1893.58, 1894.18)]:  that you can enable.
[(1894.58, 1896.96)]:  Let's look at an example of a declarative copilot.
[(1901.4, 1904.46)]:  This is what I would have deployed if I had more time.
[(1905.0, 1908.0)]:  But let's look at Adobe's declarative co-pilot
[(1908.0, 1910.0)]:  and go through that example.
[(1910.0, 1913.0)]:  As you can see, Adobe, in this scenario,
[(1913.0, 1915.0)]:  somebody is actually using Word,
[(1915.0, 1918.0)]:  and they actually want to build an Instagram campaign,
[(1918.0, 1921.0)]:  and they've instantiated a declarative co-pilot for Adobe
[(1921.0, 1923.0)]:  through Word's co-pilot experience.
[(1923.0, 1926.62)]:  And what it is actually doing is it's taking all of the Word document
[(1926.62, 1930.52)]:  and suggesting a few options to use as an Instagram campaign.
[(1930.92, 1932.54)]:  Now, they open it up in Adobe Express.
[(1932.92, 1935.7)]:  They're going and editing it in Adobe Express itself.
[(1936.12, 1940.34)]:  And you're able to actually see that the workflow is moving from Copilot
[(1940.34, 1944.2)]:  to the source application where you're going to edit that
[(1944.2, 1947.36)]:  and then go back and share it back to the team chat
[(1947.36, 1950.02)]:  where you're having where CoPilot also has access to that data.
[(1954.2, 1957.2)]:  Now, this is one thing I want to draw your attention to.
[(1957.68, 1961.36)]:  There's a session later today that focuses on this.
[(1961.48, 1964.18)]:  We don't necessarily have time today in this session to cover it.
[(1964.4, 1969.52)]:  Please go to this session, Build CoP extensions in Copilot Studio, where you'll get to build this
[(1969.52, 1976.5)]:  with Copilot Studio. Another session, there's also a lab for this session. Just a shout out to the
[(1976.5, 1982.56)]:  folks doing the lab as well. We've already just covered declarative Copilots. Let's now focus on
[(1982.56, 1986.8)]:  custom engine Copilots. Well, custom engine
[(1986.8, 1993.64)]:  co-pilots is interesting because this is the kind of scenario where we've said, hey, there are
[(1993.64, 2000.22)]:  nuances that are way more than what declarative co-pilots enables us to do. And in this scenario,
[(2000.58, 2005.48)]:  what I'm going to do is I'm going to pick my own model, add my own data, give my own logic,
[(2005.6, 2006.5)]:  have my own automation,
[(2006.84, 2009.94)]:  and essentially manage my whole stack myself.
[(2010.34, 2011.28)]:  And in that scenario,
[(2011.42, 2013.82)]:  I'm going to choose a custom engine copilot.
[(2014.32, 2018.62)]:  A custom engine copilot is basically built
[(2018.62, 2021.38)]:  with VS Code and Teams AI library,
[(2021.76, 2023.12)]:  and we're going to see that in a little bit.
[(2025.92, 2027.96)]:  So in a custom engine co-pilot,
[(2028.18, 2033.42)]:  you are effectively using it in a scenario
[(2033.42, 2037.38)]:  where your LLM of choice can be used.
[(2037.46, 2039.68)]:  You can either use Azure AI Studio, for example,
[(2039.68, 2044.52)]:  to go and select your own LLM or SLM model from there.
[(2045.34, 2048.98)]:  You can publish these co- copilots to external users.
[(2049.12, 2050.5)]:  Here's a big actual difference
[(2050.5, 2053.76)]:  between a declarative copilot and custom engine copilot.
[(2054.74, 2056.64)]:  Declarative copilots are available to users
[(2056.64, 2059.06)]:  who are in your M365 identity.
[(2059.96, 2062.0)]:  If you want to publish, let's say, to customers,
[(2062.0, 2065.32)]:  you actually go and publish as a custom engine copilot. So if you want to publish, let's say, to customers, you actually go and publish as a custom engine copilot.
[(2066.44, 2069.34)]:  So if you want to publish it into your custom UX,
[(2070.08, 2073.38)]:  you know, plus your Microsoft 365 hubs as well,
[(2073.58, 2076.28)]:  a custom engine copilot is the answer in that scenario.
[(2076.92, 2079.28)]:  It also gives you more control, obviously,
[(2079.28, 2081.7)]:  over the automations and instantiations within
[(2081.7, 2083.5)]:  and workflows that you want to plug in there.
[(2084.7, 2088.1)]:  One of the key kind of decision points you need to make
[(2088.1, 2090.46)]:  is when you're building these AI systems,
[(2090.6, 2092.06)]:  do you need custom moderation
[(2092.06, 2095.02)]:  or compliance to regulatory frameworks
[(2095.02, 2097.42)]:  and, like, you know, healthcare frameworks
[(2097.42, 2099.38)]:  and all of that or government regulations?
[(2099.68, 2102.44)]:  And for that scenario, you may need a custom engine
[(2102.44, 2104.96)]:  or, you know, custom controls that are built in
[(2104.96, 2109.14)]:  that are, you know, beyond what a natural language instruction set
[(2109.14, 2110.8)]:  on a declarative copilot may enable.
[(2110.8, 2113.28)]:  And for that reason, a custom engine copilot
[(2113.28, 2114.88)]:  is a reality requirement.
[(2117.04, 2118.2)]:  It also gives you, again,
[(2118.3, 2119.78)]:  full control of the prompt management.
[(2119.96, 2121.68)]:  You don't have to send a prompt to us.
[(2121.86, 2124.78)]:  You know, you use the prompt yourself.
[(2124.96, 2126.84)]:  You use the actions and triggers
[(2126.84, 2131.72)]:  yourself. You also build your own orchestrator on top of it. So, again, full control over that.
[(2132.72, 2137.2)]:  And then finally, if you already have investment into deterministic bots,
[(2138.06, 2142.94)]:  here's the difference. LLMs are probabilistic systems. Deterministic bots, which have
[(2142.94, 2145.26)]:  predefined workflows, and we all need them,
[(2145.62, 2148.3)]:  if those are already existing investments that you've made,
[(2149.02, 2150.98)]:  custom engine co-pilots encapsulate that
[(2150.98, 2151.8)]:  with the bot framework,
[(2151.98, 2153.8)]:  and you're able to deploy them out of that.
[(2154.76, 2157.66)]:  Now, one big thing for those of you out there
[(2157.66, 2158.62)]:  who are SaaS companies
[(2158.62, 2160.54)]:  and you want to publish this to your customers,
[(2160.96, 2162.06)]:  custom engine co-pilots,
[(2162.06, 2165.82)]:  you can publish them into the Microsoftrosoft stores as a sas provider as well.
[(2167.56, 2172.7)]:  Let's look at what actually is a custom engine co-pilot and how
[(2172.7, 2197.6)]:  You might be able to instantiate it. Let me roll the video first. So basically this is azure open ai studio.
[(2197.6, 2203.16)]:  I've actually gone in just before the session and actually instantiated a gpd 3.5 model.
[(2203.16, 2205.02)]:  You can actually go and play with it.
[(2206.72, 2210.9)]:  Effectively, what I've done in this scenario is taken, you know, a policy document,
[(2211.16, 2212.32)]:  a set of policy documents,
[(2212.42, 2215.44)]:  and inserted into OpenAI Studio
[(2215.44, 2217.8)]:  and said, hey, this is...
[(2217.8, 2220.16)]:  go and build your embeddings on top of this
[(2220.16, 2222.38)]:  and provide me a custom engine that I can work with.
[(2222.92, 2224.0)]:  Now, if you have...
[(2224.72, 2226.0)]:  if you've already done this and you have access to a custom engine that I can work with. Now, if you've already done this
[(2226.0, 2227.7)]:  and you have access to a custom model
[(2227.7, 2229.34)]:  or you're bringing your own model,
[(2229.62, 2235.98)]:  you then go in and go to your VS Code environment,
[(2236.32, 2237.96)]:  and in your VS Code environment,
[(2238.32, 2242.2)]:  you're able to then go and edit this functionality
[(2242.2, 2245.0)]:  and go and edit this functionality and go and edit the project
[(2245.0, 2247.0)]:  and basically...
[(2253.0, 2258.8)]:  I had one more video to show, actually.
[(2259.48, 2262.1)]:  You actually use Teams Toolkit in VS Code
[(2262.1, 2264.26)]:  and go and choose custom and co-pilot,
[(2264.58, 2265.3)]:  and once you
[(2265.3, 2267.94)]:  instantiate a project and you can
[(2267.94, 2269.98)]:  go and actually edit the
[(2269.98, 2271.98)]:  project inside VS Code and
[(2271.98, 2273.9)]:  publish it either to Teams or your
[(2273.9, 2276.66)]:  own custom UX.
[(2281.72, 2284.06)]:  So effectively, in VS Code,
[(2284.16, 2289.44)]:  what you're looking at is your instantiation prompt and the specifics
[(2289.44, 2294.5)]:  of the project that you need in the package that you need to deploy.
[(2294.5, 2298.24)]:  Like, for example, do you need a specific model?
[(2298.24, 2299.96)]:  What's the open AI key?
[(2299.96, 2304.14)]:  Once you specify those in your project, you can go and deploy that as your custom engine
[(2304.14, 2305.24)]:  copilot. Let's look at the example as your custom engine co-pilot.
[(2307.8, 2308.94)]:  Let's look at the example of a custom engine co-pilot deployed by Isera.
[(2309.42, 2310.66)]:  In this scenario, Isera,
[(2310.84, 2313.68)]:  the reason why they've done custom engine is because,
[(2314.3, 2315.88)]:  and they call it Isera AI co-pilot,
[(2315.88, 2319.3)]:  is because they actually have custom automation
[(2319.3, 2325.78)]:  built in to a back-end system for many, many APIs.
[(2326.56, 2330.14)]:  So it's actually way more beneficial for them
[(2330.14, 2333.18)]:  to build a copilot encapsulation on top
[(2333.18, 2335.06)]:  which instantiate that backend
[(2335.06, 2338.64)]:  instead of trying to build plugins for every single API.
[(2339.22, 2340.3)]:  And in that scenario,
[(2340.54, 2342.56)]:  they've actually built a custom engine copilot
[(2342.56, 2346.0)]:  which you can invoke from the copilot experience itself. And, youilot, which you can invoke from the co-pilot experience itself.
[(2346.0, 2350.0)]:  And, you know, as you can see on the video,
[(2350.0, 2353.0)]:  once they've invoked the custom engine co-pilot
[(2353.0, 2355.0)]:  from co-pilot experience,
[(2355.0, 2358.0)]:  you can actually go and click into that
[(2358.0, 2361.0)]:  and do a handoff to the immersive experience.
[(2361.0, 2363.0)]:  The immersive experience is basically...
[(2363.0, 2366.5)]:  It goes into a dedicated experience where a user
[(2366.5, 2372.96)]:  can chat to only the custom engine. And once they're happy with that, you know, with the chat,
[(2373.06, 2378.74)]:  and they actually keep on prompting to, let's say, in this scenario, what they've realized is they
[(2378.74, 2387.5)]:  want a meeting. And the prompt is being interpreted by the custom engine to call a meeting API, which, you know, they have developed,
[(2387.78, 2390.26)]:  and they go and book that particular meeting
[(2390.26, 2390.9)]:  in that scenario.
[(2393.78, 2396.0)]:  These custom, as we discussed before,
[(2396.1, 2397.78)]:  these custom engine copilots can be published
[(2397.78, 2399.64)]:  as copilot extensions, and you can have them
[(2399.64, 2401.74)]:  both even in the immersive experience
[(2401.74, 2405.84)]:  or in the inline copilot experience as well.
[(2407.46, 2409.88)]:  Now, I just want to call out the two sessions
[(2409.88, 2413.7)]:  that we'll be covering these copilots after this,
[(2413.8, 2415.16)]:  the Azure AI Studio session,
[(2415.26, 2416.94)]:  Creating and Scaling Your Custom Copilots,
[(2417.4, 2419.76)]:  and Build Your Own Copilot in Copilot Studio.
[(2421.02, 2428.82)]:  And if you want to dive deep on Teams AI library and how to actually go and build custom engine
[(2428.82, 2436.28)]:  copiers with VS code, here's the session breakout 146, 320 million Teams users, how to reach
[(2436.28, 2438.52)]:  them through Teams, go to that session.
[(2438.52, 2441.14)]:  I'll hand back to Jeremy.
[(2441.14, 2444.2)]:  Thank you, Barnum.
[(2444.2, 2448.06)]:  So hopefully today you've seen that we have choice.
[(2448.06, 2451.94)]:  We've given you choice whether you build on top of our AI platform or whether you bring
[(2451.94, 2453.86)]:  your own.
[(2453.86, 2457.42)]:  In a lot of the AKA links at the bottom here, you'll see that we're pointing to particular
[(2457.42, 2461.44)]:  developer center slides that the team back at base have been building to further go into
[(2461.44, 2462.76)]:  detail about some of these decisions.
[(2462.76, 2466.0)]:  We'll continue to keep revving on those as we learn from your experiences
[(2466.0, 2468.0)]:  in building on top of this.
[(2468.0, 2471.0)]:  I'd just like to pause to take thanks to all the partners we've been working with
[(2471.0, 2474.0)]:  in both the private preview and the public previews
[(2474.0, 2477.0)]:  to build these experiences and to be able to provide this type of guidance
[(2477.0, 2479.0)]:  to you at Build this week.
[(2479.0, 2486.16)]:  Now, there is a great session that Srini is doing, 147, on Thursday at 8 a.m., at 8.30 a.m., that's going to go
[(2486.16, 2490.16)]:  into a lot more detail. If you're a software vendor and you're wearing that hat, I'd encourage
[(2490.16, 2494.16)]:  you to go check out that session, as well as the transferring the most valuable industry
[(2494.16, 2497.32)]:  workflows with Copilot, which is at 3 p.m. on Thursday as well.
[(2499.0, 2510.0)]:  Now, just to recap on some of the things we've shown and what that looks like timeline-wise from roadmaps. Obviously, with Copilot Studio today, Copilot connectors are actually in public preview right
[(2510.0, 2515.96)]:  now. The plugins that we've shown you will be available in public preview right now,
[(2516.3, 2521.0)]:  and there is a sign-up sheet that you can go to at aka.ms slash copilot dash extensions,
[(2521.62, 2527.9)]:  and if you fill that form out, we'll notify you when it's available to light up in your particular tenant to use Copilot Studio plugins.
[(2527.9, 2531.3)]:  And additionally, there is a private preview going on right now if you wanted to build
[(2531.3, 2536.06)]:  your own custom engine copilots within Copilot Studio.
[(2536.06, 2539.9)]:  From a Teams toolkit and Visual Studio Code perspective, Graph connectors are generally
[(2539.9, 2543.76)]:  available and they're available as part of the Copilot for Microsoft experience in public
[(2543.76, 2549.16)]:  preview still. The Teams message extensions are still available right now in your attendance
[(2549.16, 2554.28)]:  today and coming very, very soon, API plug-ins which I demonstrated backed by those open
[(2554.28, 2560.12)]:  API documents will be available in your attendance to play with too. In addition to if you want
[(2560.12, 2568.38)]:  to build custom engine copilots in Teams AI library, those are available right standalone, and very shortly you'll be able to have that immersive experience and that
[(2568.38, 2573.2)]:  handoff from our co-pilot to your co-pilot in your public tenants too.
[(2574.72, 2578.12)]:  Now, there are a lot of sessions at Build that go into a lot more detail here.
[(2578.2, 2580.06)]:  Some of those we've called out in particular slides.
[(2580.44, 2583.66)]:  I'll give you a moment to take a picture of the screen that will cover those in more detail.
[(2590.12, 2590.7)]:  There is obviously the hall upstairs on the top floor where you'll be able to ask more questions to our experts in person.
[(2592.9, 2593.02)]:  And so just a big thank you for taking your time to take that photo.
[(2596.28, 2597.8)]:  And we hopefully see a lot of your faces in those breakouts moving forward.
[(2599.0, 2599.08)]:  So the time is now.
[(2599.92, 2607.68)]:  Go build, please. We'd love to see what you can do with taking Copilot for Microsoft 365, an AI platform or your AI platform, and helping users be more productive.
[(2608.18, 2610.26)]:  Thank you again for your time today and enjoy the rest of Build.
[(2611.7, None)]:  Thanks, Adam. you you you
